实现想法 ：
    从技术上我们可以对每一个consumer绑定重平衡的监听器
    每一个consumer重平衡的时候 把这个consumer绑定的partion 发送到redis 上（使用lua脚本实现队列不重复push，技术上可行已经实现）
    每一次重平衡的时候就删除redis的队列，然后在重平衡之后就把可用的队列发送的redis上
    
    使用一个while循环 阻塞获取redis队列中的数据即分区，获取到之后在阻塞获取本地数据队列的数据，
    都获取到了就发送到消费topic指定分区
    （存在的问题 有点担心一直都是一个节点获取到对应的数据 其他节点  数据队列会被压的特别庞大）
    
    
    对于抢占pation的算法实现 我目前是这样考虑 
    1 使用随机抢占  每一个节点开一个while 随抢占到就是谁的 看谁先执行了获取数据的redis命令
  
  
  
   
  针对本次发版 定义新得topic 那么发布A节点，新topic所有的分区被分配到A节点上，消息只会推到A上
  发布第二个节点 B kafka 重平衡 然后，A B 分区被分配到分区 ，两个节点抢占 分区 并且推送各自的数据到
   
   
   
   
   可能会在一定的间隔时间发送相同的数据的情况   
        在初始化 和 消费之后往redis队中插入了相同的数据
            测试之后 无法确定 先走哪一个 
                假设1 
                重平衡过程中 ，每一个consumer 进行冲平衡 先会走进reblance监控删除key 然后打断对应的线程运行 ，也有可能这个时候已经发送了 ，那么这个时候 就发送了一个 
                最后平衡结束 又发送了一个 这样redis 会出现两个 同样的partion
                同样我也可以在consumer 中去检查 是不是这个pation 因为一些原因导致重复了 如果重复就删除掉redis 中的那条 
                假设2 
                重平衡过程中 ，每一个consumer 进行冲平衡，先打断运行，已经执行了 redis 发送 ，那么在走进redis 监控删除key ，最后一笔来说 也没有问题 此时在kafka 平衡之后 key是空的 ，等到后 重新初始化数据   
         
        加入同时两台发生了重平衡 
            A 重平衡    发送了redis 接收 并发发送到了对应的partion 还没开始消费呢 又开始了重 接收到了 发送了 kafka  A pation 存在了数据堆积 那么 
            就会存在发送两次pation 到redis上，但也是总会出现相遇的情况，或者我们在consumer 消费时检查 ，总会在一个时刻会删除掉一个重复的
        
        某些原因导致 某一个队列堆积了两条数据 
            消费一条发送一个   又消费一个发送一个    总会出现 相遇丢弃的情况 这个时候去重我会放弃后面的那一条数据
   
       可能会出现redis 导致数据丢失的情况 如果这样，那么对应的某一个或者某几个 p 会一直得不到运行 
           可以使用一个job  每隔着几分钟检查   redis 上是不是存在数据 ，比如我检查了一小时都没有在redis 上出现过 那么我就发送一个控数据到kafka 重新加入队列上
       redis 在运行中意外key被删除了 如果这丫昂 那么对应的 所有的p 都得不到运行 ， 或者手动清空了 redis 需要通知所有的节点重新往redis 进行初始化数据 使用广播 
            上面两个·问题可以归为一个 如果数据缺失了怎么办    用一个job监控在给定次数上是否出现如果还是没有出现 就重新放回 
        
   quene 数据会丢失的问题，应该只有在系统重启上才会出现， 可以通过监控springboot 启动和关闭的事件 关闭时把数据刷新到文件或者数据库上，启动时重新读取到quene上
        
        
   
   那么 Rebalance 会在什么时候发生呢？
   
   订阅主题数发生变化 --  会导致重平衡         --- 新上版的时候修改 topic 会引起冲平衡 但是不影响使用 新旧节点正常的运行

   主题分区发生变化 ---分区发生变化    

   消费端的消费者组成员变化

   消费者处理消息超时，                       ---  因为消费之后需要阻塞发送到redis 所以有点担心会因为这个导致的超时 
   
   
    